{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yzpPFSXW-zPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "content = \"\"\"<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title>Sports World</title>\n",
        "    <style>\n",
        "        body { font-family: Arial, sans-serif; }\n",
        "        header, nav, section, article, footer { margin: 20px; padding: 15px; }\n",
        "        nav { background-color: #333; }\n",
        "        nav a { color: white; padding: 14px 20px; text-decoration: none; display: inline-block; }\n",
        "        nav a:hover { background-color: #ddd; color: black; }\n",
        "        .video { text-align: center; margin: 20px 0; }\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "\n",
        "    <header>\n",
        "        <h1>Welcome to Sports World</h1>\n",
        "        <p>Your one-stop destination for the latest sports news and videos.</p>\n",
        "    </header>\n",
        "\n",
        "    <nav>\n",
        "        <a href=\"#football\">Football</a>\n",
        "        <a href=\"#basketball\">Basketball</a>\n",
        "        <a href=\"#tennis\">Tennis</a>\n",
        "    </nav>\n",
        "\n",
        "    <section id=\"football\">\n",
        "        <h2>Football</h2>\n",
        "        <article>\n",
        "            <h3>Latest Football News</h3>\n",
        "            <p>Read about the latest football matches and player news.</p>\n",
        "            <div class=\"video\">\n",
        "                <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/football-video-id\" frameborder=\"0\" allowfullscreen>\n",
        "                </iframe>\n",
        "            </div>\n",
        "        </article>\n",
        "    </section>\n",
        "\n",
        "    <section id=\"basketball\">\n",
        "        <h2>Basketball</h2>\n",
        "        <article>\n",
        "            <h3>NBA Highlights</h3>\n",
        "            <p>Watch highlights from the latest NBA games.</p>\n",
        "            <div class=\"video\">\n",
        "                <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/basketball-video-id\" frameborder=\"0\" allowfullscreen>\n",
        "                </iframe>\n",
        "            </div>\n",
        "        </article>\n",
        "    </section>\n",
        "\n",
        "    <section id=\"tennis\">\n",
        "        <h2>Tennis</h2>\n",
        "        <article>\n",
        "            <h3>Grand Slam Updates</h3>\n",
        "            <p>Get the latest updates from the world of Grand Slam tennis.</p>\n",
        "            <div class=\"video\">\n",
        "                <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/tennis-video-id\" frameborder=\"0\" allowfullscreen></iframe>\n",
        "            </div>\n",
        "        </article>\n",
        "    </section>\n",
        "\n",
        "    <footer>\n",
        "        <form action=\"mailto:contact@sportsworld.com\" method=\"post\" enctype=\"text/plain\">\n",
        "            <label for=\"name\">Name:</label><br>\n",
        "            <input type=\"text\" id=\"name\" name=\"name\"><br>\n",
        "            <label for=\"email\">Email:</label><br>\n",
        "            <input type=\"email\" id=\"email\" name=\"email\"><br>\n",
        "            <label for=\"message\">Message:</label><br>\n",
        "            <textarea id=\"message\" name=\"message\" rows=\"4\" cols=\"50\"></textarea><br><br>\n",
        "            <input type=\"submit\" value=\"Send\">\n",
        "        </form>\n",
        "    </footer>\n",
        "\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "Zyq5eKo--5HT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read the HTML content of the page.\n",
        "Create a BeautifulSoup object to parse this HTML.\n",
        "Find the title of the webpage (the content inside the <title> tag).\n",
        "Extract all paragraphs (<p> tags) from the page.\n",
        "Retrieve all links (URLs in <a href=\"\"> tags) on the page."
      ],
      "metadata": {
        "id": "TViDD4G2_DgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "soup = BeautifulSoup(content, 'html.parser')\n",
        "# title = soup.find('title').text\n",
        "title = soup.title.string # better way imo suggested by google collab\n",
        "paragraphs = soup.find_all('p')\n",
        "links = soup.find_all('a')\n",
        "print(f\"Title: {title}\")\n",
        "print(\"Paragraphs:\")\n",
        "for paragraph in paragraphs:\n",
        "    print(paragraph.text)\n",
        "print(\"Links:\")\n",
        "for link in links:\n",
        "    print(link.get('href'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_m-Ljozp_A-A",
        "outputId": "8bde752b-3925-4614-d69a-6ea4b1ca92df"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: Sports World\n",
            "Paragraphs:\n",
            "Your one-stop destination for the latest sports news and videos.\n",
            "Read about the latest football matches and player news.\n",
            "Watch highlights from the latest NBA games.\n",
            "Get the latest updates from the world of Grand Slam tennis.\n",
            "Links:\n",
            "#football\n",
            "#basketball\n",
            "#tennis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸŒŸ Exercise 2 : Scraping robots.txt from Wikipedia\n",
        "Instructions\n",
        "Write a Python program to download and display the content of robot.txt for wikipedia"
      ],
      "metadata": {
        "id": "ZeAwOZQ9Brye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "response = requests.get(\"https://www.wikipedia.org/robots.txt\")\n",
        "print(response.text[:43])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Nt3Vdl_Bt1K",
        "outputId": "819174d7-4bab-4f53-fb67-0abde3b6e5dc"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ï»¿# robots.txt for http://www.wikipedia.org/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 3 : Extracting Headers from Wikipediaâ€™s Main Page\n",
        "Instructions\n",
        "Write a Python program to extract and display all the header tags from wikipedia."
      ],
      "metadata": {
        "id": "kzf-2h67Ek_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "headers = ['h1','h2','h3','h4','h5','h6']\n",
        "response = requests.get(\"https://www.wikipedia.org/\")\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "for header in headers:\n",
        "    print(f\"{header} tags:\")\n",
        "    for tag in soup.find_all(header):\n",
        "        print(tag.text.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xojp51HwEnrr",
        "outputId": "f5b10088-92bb-48cf-f761-3e65b7ceed3a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "h1 tags:\n",
            "Wikipedia\n",
            "\n",
            "The Free Encyclopedia\n",
            "h2 tags:\n",
            "1,000,000+\n",
            "\n",
            "\n",
            "articles\n",
            "100,000+\n",
            "\n",
            "\n",
            "articles\n",
            "10,000+\n",
            "\n",
            "\n",
            "articles\n",
            "1,000+\n",
            "\n",
            "\n",
            "articles\n",
            "100+\n",
            "\n",
            "\n",
            "articles\n",
            "h3 tags:\n",
            "The internet we were promised\n",
            "h4 tags:\n",
            "h5 tags:\n",
            "h6 tags:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "header_tags = soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])\n",
        "for tag in header_tags:\n",
        "  print(tag.text.strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-bFkXTkJnn4",
        "outputId": "a9f10809-ee3b-4aca-b9df-a2d92c048dfc"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wikipedia\n",
            "\n",
            "The Free Encyclopedia\n",
            "1,000,000+\n",
            "\n",
            "\n",
            "articles\n",
            "100,000+\n",
            "\n",
            "\n",
            "articles\n",
            "10,000+\n",
            "\n",
            "\n",
            "articles\n",
            "1,000+\n",
            "\n",
            "\n",
            "articles\n",
            "100+\n",
            "\n",
            "\n",
            "articles\n",
            "The internet we were promised\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 4 : Checking for Page Title\n",
        "Instructions\n",
        "Write a Python program to check whether a page contains a title or not."
      ],
      "metadata": {
        "id": "TTwxwrC2KgQp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_page = \"\"\"<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "</head>\n",
        "<body>\n",
        "    <h1>Welcome to the Test Page</h1>\n",
        "    <p id=\"description\">This is a simple HTML page for testing purposes.</p>\n",
        "    <ul>\n",
        "        <li class=\"item\">Item 1</li>\n",
        "        <li class=\"item\">Item 2</li>\n",
        "        <li class=\"item\">Item 3</li>\n",
        "    </ul>\n",
        "    <a href=\"https://example.com\" id=\"example-link\">Example Link</a>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "soup = BeautifulSoup(test_page, 'html.parser')\n",
        "title = soup.title\n",
        "if title:\n",
        "    print(f\"The page has a title: {title.text}\")\n",
        "else:\n",
        "    print(\"The page does not have a title.\")\n",
        "\n",
        "test_page = \"\"\"<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title>Test Page</title>\n",
        "</head>\n",
        "<body>\n",
        "    <h1>Welcome to the Test Page</h1>\n",
        "    <p id=\"description\">This is a simple HTML page for testing purposes.</p>\n",
        "    <ul>\n",
        "        <li class=\"item\">Item 1</li>\n",
        "        <li class=\"item\">Item 2</li>\n",
        "        <li class=\"item\">Item 3</li>\n",
        "    </ul>\n",
        "    <a href=\"https://example.com\" id=\"example-link\">Example Link</a>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "soup = BeautifulSoup(test_page, 'html.parser')\n",
        "title = soup.title\n",
        "if title:\n",
        "    print(f\"The page 2 has a title: {title.text}\")\n",
        "else:\n",
        "    print(\"The page 2 does not have a title.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTbSX4qyKk_1",
        "outputId": "5dd87b42-261d-425c-ac9f-b2fa9b83563c"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The page does not have a title.\n",
            "The page 2 has a title: Test Page\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Exercise 5 : Analyzing US-CERT Security Alerts\n",
        "Instructions\n",
        "Write a Python program to get the number of security alerts issued by US-CERT in the current year.\n",
        "Source"
      ],
      "metadata": {
        "id": "G_VE9LKtMFNP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "page = 0\n",
        "current_year = datetime.now().year\n",
        "alerts_count = 0\n",
        "while current_year == 2024:\n",
        "  response = requests.get(f'https://www.cisa.gov/news-events/cybersecurity-advisories?f%5B0%5D=advisory_type%3A93&page={page}')\n",
        "  soup = BeautifulSoup(response.text, 'html.parser')\n",
        "  alerts = soup.find_all(class_='c-teaser__date')\n",
        "  for alert in alerts:\n",
        "    date = alert.find('time').get('datetime')\n",
        "    date_obj = datetime.strptime(date, '%Y-%m-%dT%H:%M:%S%z')\n",
        "    if date_obj.year == current_year:\n",
        "      alerts_count += 1\n",
        "    else:\n",
        "      current_year = 2023\n",
        "  page+=1\n",
        "print(alerts_count)\n",
        "\n",
        "# tbh I'm not sure how to check this number except for manually but code seems and feels right so I guess its 369...\n",
        "# a bit bulky but not sure how to do it in other way except for maybe some polishing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w28sttfPOZg9",
        "outputId": "21c7091c-7fec-4503-d079-5a377252d378"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "369\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Exercise 6 : Scraping Movie Details\n",
        "Instructions\n",
        "Write a Python program to get movie name, year and a brief summary of the top 10 random movies from this IMBD website.\n",
        "\n"
      ],
      "metadata": {
        "id": "klimPeP2R8ql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "hockey = 'https://www.scrapethissite.com/pages/forms/'\n",
        "response = requests.get(hockey)\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "hockey = soup.find_all('tr', class_='team')\n",
        "hockey_ids = np.random.choice(len(hockey), 10, replace=False)\n",
        "teams = []\n",
        "for i in hockey_ids:\n",
        "  team = {'Name': '', 'Year':'' ,'Wins':'', 'Losses':'' }\n",
        "  team['Name'] = hockey[i].find('td', class_='name').text.strip()\n",
        "  team['Year'] = hockey[i].find('td', class_='year').text.strip()\n",
        "  team['Wins'] = hockey[i].find('td', class_='wins').text.strip()\n",
        "  team['Losses'] = hockey[i].find('td', class_='losses').text.strip()\n",
        "  teams.append(team)\n",
        "for team in teams:\n",
        "  print(team)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGVO1P00R9iz",
        "outputId": "9e949a4d-4e22-4fb8-924a-a77a1efa36fa"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Name': 'Minnesota North Stars', 'Year': '1990', 'Wins': '27', 'Losses': '39'}\n",
            "{'Name': 'St. Louis Blues', 'Year': '1990', 'Wins': '47', 'Losses': '22'}\n",
            "{'Name': 'Boston Bruins', 'Year': '1990', 'Wins': '44', 'Losses': '24'}\n",
            "{'Name': 'Calgary Flames', 'Year': '1991', 'Wins': '31', 'Losses': '37'}\n",
            "{'Name': 'New York Islanders', 'Year': '1990', 'Wins': '25', 'Losses': '45'}\n",
            "{'Name': 'Montreal Canadiens', 'Year': '1990', 'Wins': '39', 'Losses': '30'}\n",
            "{'Name': 'Philadelphia Flyers', 'Year': '1990', 'Wins': '33', 'Losses': '37'}\n",
            "{'Name': 'Buffalo Sabres', 'Year': '1990', 'Wins': '31', 'Losses': '30'}\n",
            "{'Name': 'Buffalo Sabres', 'Year': '1991', 'Wins': '31', 'Losses': '37'}\n",
            "{'Name': 'Edmonton Oilers', 'Year': '1990', 'Wins': '37', 'Losses': '37'}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}